{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: gensim in c:\\users\\s164937\\anaconda3\\lib\\site-packages (3.8.3)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.18.1 in c:\\users\\s164937\\anaconda3\\lib\\site-packages (from gensim) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: Cython==0.29.14 in c:\\users\\s164937\\anaconda3\\lib\\site-packages (from gensim) (0.29.14)\n",
      "Requirement already satisfied, skipping upgrade: smart-open>=1.8.1 in c:\\users\\s164937\\anaconda3\\lib\\site-packages (from gensim) (3.0.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.11.3 in c:\\users\\s164937\\anaconda3\\lib\\site-packages (from gensim) (1.18.5)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5.0 in c:\\users\\s164937\\anaconda3\\lib\\site-packages (from gensim) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: requests in c:\\users\\s164937\\anaconda3\\lib\\site-packages (from smart-open>=1.8.1->gensim) (2.24.0)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\s164937\\anaconda3\\lib\\site-packages (from requests->smart-open>=1.8.1->gensim) (1.25.9)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in c:\\users\\s164937\\anaconda3\\lib\\site-packages (from requests->smart-open>=1.8.1->gensim) (2.10)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in c:\\users\\s164937\\anaconda3\\lib\\site-packages (from requests->smart-open>=1.8.1->gensim) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in c:\\users\\s164937\\anaconda3\\lib\\site-packages (from requests->smart-open>=1.8.1->gensim) (2020.6.20)\n",
      "Requirement already up-to-date: keras in c:\\users\\s164937\\anaconda3\\lib\\site-packages (2.4.3)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.14 in c:\\users\\s164937\\anaconda3\\lib\\site-packages (from keras) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.9.1 in c:\\users\\s164937\\anaconda3\\lib\\site-packages (from keras) (1.18.5)\n",
      "Requirement already satisfied, skipping upgrade: h5py in c:\\users\\s164937\\anaconda3\\lib\\site-packages (from keras) (2.10.0)\n",
      "Requirement already satisfied, skipping upgrade: pyyaml in c:\\users\\s164937\\anaconda3\\lib\\site-packages (from keras) (5.3.1)\n",
      "Requirement already satisfied, skipping upgrade: six in c:\\users\\s164937\\anaconda3\\lib\\site-packages (from h5py->keras) (1.15.0)\n",
      "Requirement already up-to-date: pandas in c:\\users\\s164937\\anaconda3\\lib\\site-packages (1.1.3)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in c:\\users\\s164937\\anaconda3\\lib\\site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.15.4 in c:\\users\\s164937\\anaconda3\\lib\\site-packages (from pandas) (1.18.5)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in c:\\users\\s164937\\anaconda3\\lib\\site-packages (from pandas) (2020.1)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5 in c:\\users\\s164937\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim --upgrade\n",
    "!pip install keras --upgrade\n",
    "!pip install pandas --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: pip in c:\\users\\s164937\\anaconda3\\lib\\site-packages (20.2.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install pip --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!pip install --user virtualenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: virtualenv in c:\\users\\s164937\\appdata\\roaming\\python\\python38\\site-packages (20.1.0)\n",
      "Requirement already satisfied: filelock<4,>=3.0.0 in c:\\users\\s164937\\anaconda3\\lib\\site-packages (from virtualenv) (3.0.12)\n",
      "Requirement already satisfied: six<2,>=1.9.0 in c:\\users\\s164937\\anaconda3\\lib\\site-packages (from virtualenv) (1.15.0)\n",
      "Requirement already satisfied: distlib<1,>=0.3.1 in c:\\users\\s164937\\appdata\\roaming\\python\\python38\\site-packages (from virtualenv) (0.3.1)\n",
      "Requirement already satisfied: appdirs<2,>=1.4.3 in c:\\users\\s164937\\appdata\\roaming\\python\\python38\\site-packages (from virtualenv) (1.4.4)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "# Matplot\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, Dropout, Embedding, Flatten, Conv1D, MaxPooling1D, LSTM\n",
    "from keras import utils\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "# nltk\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from  nltk.stem import SnowballStemmer\n",
    "\n",
    "# Word2vec\n",
    "import gensim\n",
    "\n",
    "# Utility\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import Counter\n",
    "import logging\n",
    "import time\n",
    "import pickle\n",
    "import itertools\n",
    "\n",
    "#load\n",
    "\n",
    "from numpy import loadtxt\n",
    "from keras.models import load_model\n",
    "\n",
    "# Set log\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\s164937\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASET\n",
    "DATASET_COLUMNS = [\"target\", \"ids\", \"date\", \"flag\", \"user\", \"text\"]\n",
    "DATASET_ENCODING = \"ISO-8859-1\"\n",
    "TRAIN_SIZE = 0.8\n",
    "\n",
    "# TEXT CLENAING\n",
    "TEXT_CLEANING_RE = \"@\\S+|https?:\\S+|http?:\\S|[^A-Za-z0-9]+\"\n",
    "\n",
    "# WORD2VEC \n",
    "W2V_SIZE = 300\n",
    "W2V_WINDOW = 7\n",
    "W2V_EPOCH = 32\n",
    "W2V_MIN_COUNT = 10\n",
    "\n",
    "# KERAS\n",
    "SEQUENCE_LENGTH = 300\n",
    "EPOCHS = 8\n",
    "BATCH_SIZE = 1024\n",
    "\n",
    "# SENTIMENT\n",
    "POSITIVE = \"POSITIVE\"\n",
    "NEGATIVE = \"NEGATIVE\"\n",
    "NEUTRAL = \"NEUTRAL\"\n",
    "SENTIMENT_THRESHOLDS = (0.4, 0.7)\n",
    "\n",
    "# EXPORT\n",
    "KERAS_MODEL = \"model.h5\"\n",
    "WORD2VEC_MODEL = \"model.w2v\"\n",
    "TOKENIZER_MODEL = \"tokenizer.pkl\"\n",
    "ENCODER_MODEL = \"encoder.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open file: ..\\input\\training.1600000.processed.noemoticon.csv\n"
     ]
    }
   ],
   "source": [
    "dataset_filename = os.listdir(\"../input\")[0]\n",
    "dataset_path = os.path.join(\"..\",\"input\",dataset_filename)\n",
    "print(\"Open file:\", dataset_path)\n",
    "df = pd.read_csv(dataset_path, encoding =DATASET_ENCODING , names=DATASET_COLUMNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 1600000\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset size:\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target         ids                          date      flag  \\\n",
       "0       0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1       0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2       0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3       0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4       0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "\n",
       "              user                                               text  \n",
       "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1    scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2         mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3          ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4           Karoli  @nationwideclass no, it's not behaving at all....  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map target label to String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_map = {0: \"NEGATIVE\", 2: \"NEUTRAL\", 4: \"POSITIVE\"}\n",
    "def decode_sentiment(label):\n",
    "    return decode_map[int(label)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.12 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df.target = df.target.apply(lambda x: decode_sentiment(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Dataset labels distribuition')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "target_cnt = Counter(df.target)\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.bar(target_cnt.keys(), target_cnt.values())\n",
    "plt.title(\"Dataset labels distribuition\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-Process dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words(\"english\")\n",
    "stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text, stem=False):\n",
    "    # Remove link,user and special characters\n",
    "    text = re.sub(TEXT_CLEANING_RE, ' ', str(text).lower()).strip()\n",
    "    tokens = []\n",
    "    for token in text.split():\n",
    "        if token not in stop_words:\n",
    "            if stem:\n",
    "                tokens.append(stemmer.stem(token))\n",
    "            else:\n",
    "                tokens.append(token)\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df.text = df.text.apply(lambda x: preprocess(x))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Split train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN size: 1280000\n",
      "TEST size: 320000\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=1-TRAIN_SIZE, random_state=42)\n",
    "print(\"TRAIN size:\", len(df_train))\n",
    "print(\"TEST size:\", len(df_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 14.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "documents = [_text.split() for _text in df_train.text] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = gensim.models.word2vec.Word2Vec(size=W2V_SIZE, \n",
    "                                            window=W2V_WINDOW, \n",
    "                                            min_count=W2V_MIN_COUNT, \n",
    "                                            workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-30 13:57:13,729 : INFO : collecting all words and their counts\n",
      "2020-10-30 13:57:13,732 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-10-30 13:57:13,834 : INFO : PROGRESS: at sentence #10000, processed 72565 words, keeping 14005 word types\n",
      "2020-10-30 13:57:13,971 : INFO : PROGRESS: at sentence #20000, processed 144393 words, keeping 21587 word types\n",
      "2020-10-30 13:57:14,224 : INFO : PROGRESS: at sentence #30000, processed 215826 words, keeping 27541 word types\n",
      "2020-10-30 13:57:14,417 : INFO : PROGRESS: at sentence #40000, processed 288271 words, keeping 32764 word types\n",
      "2020-10-30 13:57:14,581 : INFO : PROGRESS: at sentence #50000, processed 359772 words, keeping 37587 word types\n",
      "2020-10-30 13:57:14,725 : INFO : PROGRESS: at sentence #60000, processed 431431 words, keeping 42198 word types\n",
      "2020-10-30 13:57:14,881 : INFO : PROGRESS: at sentence #70000, processed 503103 words, keeping 46458 word types\n",
      "2020-10-30 13:57:15,017 : INFO : PROGRESS: at sentence #80000, processed 575709 words, keeping 50476 word types\n",
      "2020-10-30 13:57:15,186 : INFO : PROGRESS: at sentence #90000, processed 647100 words, keeping 54140 word types\n",
      "2020-10-30 13:57:15,319 : INFO : PROGRESS: at sentence #100000, processed 718681 words, keeping 57777 word types\n",
      "2020-10-30 13:57:15,451 : INFO : PROGRESS: at sentence #110000, processed 790696 words, keeping 61207 word types\n",
      "2020-10-30 13:57:15,578 : INFO : PROGRESS: at sentence #120000, processed 863134 words, keeping 64583 word types\n",
      "2020-10-30 13:57:15,738 : INFO : PROGRESS: at sentence #130000, processed 935111 words, keeping 67865 word types\n",
      "2020-10-30 13:57:15,897 : INFO : PROGRESS: at sentence #140000, processed 1006668 words, keeping 70966 word types\n",
      "2020-10-30 13:57:16,024 : INFO : PROGRESS: at sentence #150000, processed 1078512 words, keeping 74119 word types\n",
      "2020-10-30 13:57:16,163 : INFO : PROGRESS: at sentence #160000, processed 1149914 words, keeping 77187 word types\n",
      "2020-10-30 13:57:16,372 : INFO : PROGRESS: at sentence #170000, processed 1222145 words, keeping 80267 word types\n",
      "2020-10-30 13:57:16,561 : INFO : PROGRESS: at sentence #180000, processed 1294708 words, keeping 83393 word types\n",
      "2020-10-30 13:57:16,757 : INFO : PROGRESS: at sentence #190000, processed 1367608 words, keeping 86329 word types\n",
      "2020-10-30 13:57:16,931 : INFO : PROGRESS: at sentence #200000, processed 1439469 words, keeping 89103 word types\n",
      "2020-10-30 13:57:17,066 : INFO : PROGRESS: at sentence #210000, processed 1512099 words, keeping 91840 word types\n",
      "2020-10-30 13:57:17,225 : INFO : PROGRESS: at sentence #220000, processed 1584149 words, keeping 94636 word types\n",
      "2020-10-30 13:57:17,370 : INFO : PROGRESS: at sentence #230000, processed 1656354 words, keeping 97353 word types\n",
      "2020-10-30 13:57:17,514 : INFO : PROGRESS: at sentence #240000, processed 1728573 words, keeping 99975 word types\n",
      "2020-10-30 13:57:17,682 : INFO : PROGRESS: at sentence #250000, processed 1801102 words, keeping 102594 word types\n",
      "2020-10-30 13:57:17,854 : INFO : PROGRESS: at sentence #260000, processed 1873103 words, keeping 105162 word types\n",
      "2020-10-30 13:57:18,060 : INFO : PROGRESS: at sentence #270000, processed 1945245 words, keeping 107626 word types\n",
      "2020-10-30 13:57:18,240 : INFO : PROGRESS: at sentence #280000, processed 2017163 words, keeping 110141 word types\n",
      "2020-10-30 13:57:18,472 : INFO : PROGRESS: at sentence #290000, processed 2089574 words, keeping 112539 word types\n",
      "2020-10-30 13:57:18,666 : INFO : PROGRESS: at sentence #300000, processed 2160996 words, keeping 114893 word types\n",
      "2020-10-30 13:57:18,884 : INFO : PROGRESS: at sentence #310000, processed 2232913 words, keeping 117298 word types\n",
      "2020-10-30 13:57:19,066 : INFO : PROGRESS: at sentence #320000, processed 2305039 words, keeping 119693 word types\n",
      "2020-10-30 13:57:19,230 : INFO : PROGRESS: at sentence #330000, processed 2377119 words, keeping 122131 word types\n",
      "2020-10-30 13:57:19,414 : INFO : PROGRESS: at sentence #340000, processed 2449370 words, keeping 124416 word types\n",
      "2020-10-30 13:57:19,569 : INFO : PROGRESS: at sentence #350000, processed 2521564 words, keeping 126669 word types\n",
      "2020-10-30 13:57:19,742 : INFO : PROGRESS: at sentence #360000, processed 2593681 words, keeping 128912 word types\n",
      "2020-10-30 13:57:19,920 : INFO : PROGRESS: at sentence #370000, processed 2665692 words, keeping 131135 word types\n",
      "2020-10-30 13:57:20,069 : INFO : PROGRESS: at sentence #380000, processed 2737859 words, keeping 133403 word types\n",
      "2020-10-30 13:57:20,286 : INFO : PROGRESS: at sentence #390000, processed 2809848 words, keeping 135551 word types\n",
      "2020-10-30 13:57:20,461 : INFO : PROGRESS: at sentence #400000, processed 2882438 words, keeping 137742 word types\n",
      "2020-10-30 13:57:20,639 : INFO : PROGRESS: at sentence #410000, processed 2954075 words, keeping 139909 word types\n",
      "2020-10-30 13:57:20,828 : INFO : PROGRESS: at sentence #420000, processed 3026247 words, keeping 142144 word types\n",
      "2020-10-30 13:57:21,008 : INFO : PROGRESS: at sentence #430000, processed 3098659 words, keeping 144364 word types\n",
      "2020-10-30 13:57:21,209 : INFO : PROGRESS: at sentence #440000, processed 3170663 words, keeping 146439 word types\n",
      "2020-10-30 13:57:21,361 : INFO : PROGRESS: at sentence #450000, processed 3243344 words, keeping 148526 word types\n",
      "2020-10-30 13:57:21,500 : INFO : PROGRESS: at sentence #460000, processed 3315466 words, keeping 150610 word types\n",
      "2020-10-30 13:57:21,661 : INFO : PROGRESS: at sentence #470000, processed 3388295 words, keeping 152737 word types\n",
      "2020-10-30 13:57:21,822 : INFO : PROGRESS: at sentence #480000, processed 3460120 words, keeping 154757 word types\n",
      "2020-10-30 13:57:22,008 : INFO : PROGRESS: at sentence #490000, processed 3531883 words, keeping 156825 word types\n",
      "2020-10-30 13:57:22,200 : INFO : PROGRESS: at sentence #500000, processed 3604217 words, keeping 158859 word types\n",
      "2020-10-30 13:57:22,378 : INFO : PROGRESS: at sentence #510000, processed 3676427 words, keeping 160852 word types\n",
      "2020-10-30 13:57:22,545 : INFO : PROGRESS: at sentence #520000, processed 3749045 words, keeping 162863 word types\n",
      "2020-10-30 13:57:22,719 : INFO : PROGRESS: at sentence #530000, processed 3821622 words, keeping 164929 word types\n",
      "2020-10-30 13:57:22,917 : INFO : PROGRESS: at sentence #540000, processed 3893627 words, keeping 166840 word types\n",
      "2020-10-30 13:57:23,092 : INFO : PROGRESS: at sentence #550000, processed 3965477 words, keeping 168799 word types\n",
      "2020-10-30 13:57:23,292 : INFO : PROGRESS: at sentence #560000, processed 4038050 words, keeping 170802 word types\n",
      "2020-10-30 13:57:23,465 : INFO : PROGRESS: at sentence #570000, processed 4110296 words, keeping 172760 word types\n",
      "2020-10-30 13:57:23,652 : INFO : PROGRESS: at sentence #580000, processed 4182385 words, keeping 174635 word types\n",
      "2020-10-30 13:57:23,941 : INFO : PROGRESS: at sentence #590000, processed 4254632 words, keeping 176470 word types\n",
      "2020-10-30 13:57:24,132 : INFO : PROGRESS: at sentence #600000, processed 4326859 words, keeping 178350 word types\n",
      "2020-10-30 13:57:24,329 : INFO : PROGRESS: at sentence #610000, processed 4399183 words, keeping 180290 word types\n",
      "2020-10-30 13:57:24,497 : INFO : PROGRESS: at sentence #620000, processed 4471343 words, keeping 182129 word types\n",
      "2020-10-30 13:57:24,677 : INFO : PROGRESS: at sentence #630000, processed 4543286 words, keeping 184005 word types\n",
      "2020-10-30 13:57:24,834 : INFO : PROGRESS: at sentence #640000, processed 4615780 words, keeping 185835 word types\n",
      "2020-10-30 13:57:25,005 : INFO : PROGRESS: at sentence #650000, processed 4688481 words, keeping 187705 word types\n",
      "2020-10-30 13:57:25,196 : INFO : PROGRESS: at sentence #660000, processed 4760481 words, keeping 189439 word types\n",
      "2020-10-30 13:57:25,385 : INFO : PROGRESS: at sentence #670000, processed 4833024 words, keeping 191232 word types\n",
      "2020-10-30 13:57:25,541 : INFO : PROGRESS: at sentence #680000, processed 4904516 words, keeping 193177 word types\n",
      "2020-10-30 13:57:25,717 : INFO : PROGRESS: at sentence #690000, processed 4976968 words, keeping 194960 word types\n",
      "2020-10-30 13:57:25,906 : INFO : PROGRESS: at sentence #700000, processed 5049412 words, keeping 196725 word types\n",
      "2020-10-30 13:57:26,090 : INFO : PROGRESS: at sentence #710000, processed 5121976 words, keeping 198516 word types\n",
      "2020-10-30 13:57:26,310 : INFO : PROGRESS: at sentence #720000, processed 5193881 words, keeping 200325 word types\n",
      "2020-10-30 13:57:26,535 : INFO : PROGRESS: at sentence #730000, processed 5265467 words, keeping 202133 word types\n",
      "2020-10-30 13:57:26,748 : INFO : PROGRESS: at sentence #740000, processed 5337518 words, keeping 203818 word types\n",
      "2020-10-30 13:57:26,977 : INFO : PROGRESS: at sentence #750000, processed 5409321 words, keeping 205535 word types\n",
      "2020-10-30 13:57:27,177 : INFO : PROGRESS: at sentence #760000, processed 5481512 words, keeping 207282 word types\n",
      "2020-10-30 13:57:27,354 : INFO : PROGRESS: at sentence #770000, processed 5554093 words, keeping 209076 word types\n",
      "2020-10-30 13:57:27,553 : INFO : PROGRESS: at sentence #780000, processed 5625382 words, keeping 210805 word types\n",
      "2020-10-30 13:57:27,743 : INFO : PROGRESS: at sentence #790000, processed 5698066 words, keeping 212618 word types\n",
      "2020-10-30 13:57:27,940 : INFO : PROGRESS: at sentence #800000, processed 5770880 words, keeping 214374 word types\n",
      "2020-10-30 13:57:28,158 : INFO : PROGRESS: at sentence #810000, processed 5843418 words, keeping 216009 word types\n",
      "2020-10-30 13:57:28,349 : INFO : PROGRESS: at sentence #820000, processed 5915628 words, keeping 217804 word types\n",
      "2020-10-30 13:57:28,539 : INFO : PROGRESS: at sentence #830000, processed 5987499 words, keeping 219585 word types\n",
      "2020-10-30 13:57:28,718 : INFO : PROGRESS: at sentence #840000, processed 6058973 words, keeping 221344 word types\n",
      "2020-10-30 13:57:28,919 : INFO : PROGRESS: at sentence #850000, processed 6131125 words, keeping 223002 word types\n",
      "2020-10-30 13:57:29,112 : INFO : PROGRESS: at sentence #860000, processed 6202951 words, keeping 224643 word types\n",
      "2020-10-30 13:57:29,289 : INFO : PROGRESS: at sentence #870000, processed 6275461 words, keeping 226362 word types\n",
      "2020-10-30 13:57:29,491 : INFO : PROGRESS: at sentence #880000, processed 6347661 words, keeping 227986 word types\n",
      "2020-10-30 13:57:29,633 : INFO : PROGRESS: at sentence #890000, processed 6419806 words, keeping 229634 word types\n",
      "2020-10-30 13:57:29,809 : INFO : PROGRESS: at sentence #900000, processed 6491644 words, keeping 231389 word types\n",
      "2020-10-30 13:57:30,010 : INFO : PROGRESS: at sentence #910000, processed 6564022 words, keeping 233050 word types\n",
      "2020-10-30 13:57:30,191 : INFO : PROGRESS: at sentence #920000, processed 6636228 words, keeping 234686 word types\n",
      "2020-10-30 13:57:30,400 : INFO : PROGRESS: at sentence #930000, processed 6708573 words, keeping 236393 word types\n",
      "2020-10-30 13:57:30,569 : INFO : PROGRESS: at sentence #940000, processed 6779956 words, keeping 238052 word types\n",
      "2020-10-30 13:57:30,769 : INFO : PROGRESS: at sentence #950000, processed 6852599 words, keeping 239716 word types\n",
      "2020-10-30 13:57:30,952 : INFO : PROGRESS: at sentence #960000, processed 6924717 words, keeping 241354 word types\n",
      "2020-10-30 13:57:31,135 : INFO : PROGRESS: at sentence #970000, processed 6996992 words, keeping 242980 word types\n",
      "2020-10-30 13:57:31,316 : INFO : PROGRESS: at sentence #980000, processed 7068402 words, keeping 244646 word types\n",
      "2020-10-30 13:57:31,508 : INFO : PROGRESS: at sentence #990000, processed 7140346 words, keeping 246186 word types\n",
      "2020-10-30 13:57:31,664 : INFO : PROGRESS: at sentence #1000000, processed 7211757 words, keeping 247726 word types\n",
      "2020-10-30 13:57:31,848 : INFO : PROGRESS: at sentence #1010000, processed 7283267 words, keeping 249288 word types\n",
      "2020-10-30 13:57:32,045 : INFO : PROGRESS: at sentence #1020000, processed 7355299 words, keeping 250860 word types\n",
      "2020-10-30 13:57:32,268 : INFO : PROGRESS: at sentence #1030000, processed 7426918 words, keeping 252366 word types\n",
      "2020-10-30 13:57:32,424 : INFO : PROGRESS: at sentence #1040000, processed 7498815 words, keeping 253930 word types\n",
      "2020-10-30 13:57:32,618 : INFO : PROGRESS: at sentence #1050000, processed 7570499 words, keeping 255471 word types\n",
      "2020-10-30 13:57:32,787 : INFO : PROGRESS: at sentence #1060000, processed 7643251 words, keeping 257035 word types\n",
      "2020-10-30 13:57:32,975 : INFO : PROGRESS: at sentence #1070000, processed 7714721 words, keeping 258509 word types\n",
      "2020-10-30 13:57:33,141 : INFO : PROGRESS: at sentence #1080000, processed 7787371 words, keeping 260071 word types\n",
      "2020-10-30 13:57:33,298 : INFO : PROGRESS: at sentence #1090000, processed 7859336 words, keeping 261683 word types\n",
      "2020-10-30 13:57:33,463 : INFO : PROGRESS: at sentence #1100000, processed 7932029 words, keeping 263278 word types\n",
      "2020-10-30 13:57:33,655 : INFO : PROGRESS: at sentence #1110000, processed 8004146 words, keeping 264800 word types\n",
      "2020-10-30 13:57:33,827 : INFO : PROGRESS: at sentence #1120000, processed 8075880 words, keeping 266309 word types\n",
      "2020-10-30 13:57:34,026 : INFO : PROGRESS: at sentence #1130000, processed 8148163 words, keeping 267826 word types\n",
      "2020-10-30 13:57:34,242 : INFO : PROGRESS: at sentence #1140000, processed 8220487 words, keeping 269391 word types\n",
      "2020-10-30 13:57:34,441 : INFO : PROGRESS: at sentence #1150000, processed 8292498 words, keeping 270894 word types\n",
      "2020-10-30 13:57:34,625 : INFO : PROGRESS: at sentence #1160000, processed 8363838 words, keeping 272400 word types\n",
      "2020-10-30 13:57:34,866 : INFO : PROGRESS: at sentence #1170000, processed 8435510 words, keeping 273970 word types\n",
      "2020-10-30 13:57:35,061 : INFO : PROGRESS: at sentence #1180000, processed 8507795 words, keeping 275521 word types\n",
      "2020-10-30 13:57:35,282 : INFO : PROGRESS: at sentence #1190000, processed 8579080 words, keeping 277007 word types\n",
      "2020-10-30 13:57:35,474 : INFO : PROGRESS: at sentence #1200000, processed 8650606 words, keeping 278457 word types\n",
      "2020-10-30 13:57:35,613 : INFO : PROGRESS: at sentence #1210000, processed 8721893 words, keeping 279959 word types\n",
      "2020-10-30 13:57:35,802 : INFO : PROGRESS: at sentence #1220000, processed 8793795 words, keeping 281427 word types\n",
      "2020-10-30 13:57:35,982 : INFO : PROGRESS: at sentence #1230000, processed 8865726 words, keeping 282981 word types\n",
      "2020-10-30 13:57:36,172 : INFO : PROGRESS: at sentence #1240000, processed 8938173 words, keeping 284542 word types\n",
      "2020-10-30 13:57:36,360 : INFO : PROGRESS: at sentence #1250000, processed 9010842 words, keeping 286064 word types\n",
      "2020-10-30 13:57:36,515 : INFO : PROGRESS: at sentence #1260000, processed 9083261 words, keeping 287521 word types\n",
      "2020-10-30 13:57:36,670 : INFO : PROGRESS: at sentence #1270000, processed 9155616 words, keeping 288987 word types\n",
      "2020-10-30 13:57:36,872 : INFO : collected 290418 word types from a corpus of 9227204 raw words and 1280000 sentences\n",
      "2020-10-30 13:57:36,875 : INFO : Loading a fresh vocabulary\n",
      "2020-10-30 13:57:37,897 : INFO : effective_min_count=10 retains 30369 unique words (10% of original 290418, drops 260049)\n",
      "2020-10-30 13:57:37,903 : INFO : effective_min_count=10 leaves 8780739 word corpus (95% of original 9227204, drops 446465)\n",
      "2020-10-30 13:57:38,475 : INFO : deleting the raw counts dictionary of 290418 items\n",
      "2020-10-30 13:57:38,503 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2020-10-30 13:57:38,511 : INFO : downsampling leaves estimated 8222658 word corpus (93.6% of prior 8780739)\n",
      "2020-10-30 13:57:39,078 : INFO : estimated required memory for 30369 words and 300 dimensions: 88070100 bytes\n",
      "2020-10-30 13:57:39,081 : INFO : resetting layer weights\n"
     ]
    }
   ],
   "source": [
    "w2v_model.build_vocab(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size 30369\n"
     ]
    }
   ],
   "source": [
    "words = w2v_model.wv.vocab.keys()\n",
    "vocab_size = len(words)\n",
    "print(\"Vocab size\", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-30 13:58:25,582 : INFO : training model with 8 workers on 30369 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=7\n",
      "2020-10-30 13:58:26,687 : INFO : EPOCH 1 - PROGRESS: at 1.95% examples, 150716 words/s, in_qsize 15, out_qsize 0\n",
      "2020-10-30 13:58:27,693 : INFO : EPOCH 1 - PROGRESS: at 5.22% examples, 206523 words/s, in_qsize 14, out_qsize 0\n",
      "2020-10-30 13:58:28,725 : INFO : EPOCH 1 - PROGRESS: at 8.26% examples, 218306 words/s, in_qsize 15, out_qsize 0\n",
      "2020-10-30 13:58:29,738 : INFO : EPOCH 1 - PROGRESS: at 11.30% examples, 225194 words/s, in_qsize 15, out_qsize 0\n",
      "2020-10-30 13:58:30,740 : INFO : EPOCH 1 - PROGRESS: at 14.32% examples, 229775 words/s, in_qsize 14, out_qsize 0\n",
      "2020-10-30 13:58:31,742 : INFO : EPOCH 1 - PROGRESS: at 17.13% examples, 229981 words/s, in_qsize 15, out_qsize 2\n",
      "2020-10-30 13:58:32,797 : INFO : EPOCH 1 - PROGRESS: at 20.38% examples, 233419 words/s, in_qsize 16, out_qsize 0\n",
      "2020-10-30 13:58:33,811 : INFO : EPOCH 1 - PROGRESS: at 23.09% examples, 231751 words/s, in_qsize 15, out_qsize 0\n",
      "2020-10-30 13:58:34,838 : INFO : EPOCH 1 - PROGRESS: at 26.02% examples, 232010 words/s, in_qsize 14, out_qsize 1\n",
      "2020-10-30 13:58:35,841 : INFO : EPOCH 1 - PROGRESS: at 29.05% examples, 233657 words/s, in_qsize 16, out_qsize 0\n",
      "2020-10-30 13:58:36,891 : INFO : EPOCH 1 - PROGRESS: at 31.97% examples, 233218 words/s, in_qsize 15, out_qsize 1\n",
      "2020-10-30 13:58:37,924 : INFO : EPOCH 1 - PROGRESS: at 34.78% examples, 232448 words/s, in_qsize 15, out_qsize 1\n",
      "2020-10-30 13:58:38,972 : INFO : EPOCH 1 - PROGRESS: at 38.14% examples, 234858 words/s, in_qsize 14, out_qsize 1\n",
      "2020-10-30 13:58:40,021 : INFO : EPOCH 1 - PROGRESS: at 41.16% examples, 235090 words/s, in_qsize 16, out_qsize 0\n",
      "2020-10-30 13:58:41,029 : INFO : EPOCH 1 - PROGRESS: at 43.64% examples, 233003 words/s, in_qsize 15, out_qsize 1\n",
      "2020-10-30 13:58:42,056 : INFO : EPOCH 1 - PROGRESS: at 46.99% examples, 235263 words/s, in_qsize 14, out_qsize 1\n",
      "2020-10-30 13:58:43,058 : INFO : EPOCH 1 - PROGRESS: at 49.70% examples, 234528 words/s, in_qsize 14, out_qsize 2\n",
      "2020-10-30 13:58:44,121 : INFO : EPOCH 1 - PROGRESS: at 52.62% examples, 234061 words/s, in_qsize 15, out_qsize 0\n",
      "2020-10-30 13:58:45,154 : INFO : EPOCH 1 - PROGRESS: at 55.64% examples, 234465 words/s, in_qsize 16, out_qsize 1\n",
      "2020-10-30 13:58:46,174 : INFO : EPOCH 1 - PROGRESS: at 58.47% examples, 234110 words/s, in_qsize 16, out_qsize 0\n",
      "2020-10-30 13:58:47,201 : INFO : EPOCH 1 - PROGRESS: at 61.39% examples, 234121 words/s, in_qsize 15, out_qsize 1\n",
      "2020-10-30 13:58:48,232 : INFO : EPOCH 1 - PROGRESS: at 64.51% examples, 234857 words/s, in_qsize 15, out_qsize 0\n",
      "2020-10-30 13:58:49,270 : INFO : EPOCH 1 - PROGRESS: at 66.80% examples, 232447 words/s, in_qsize 16, out_qsize 0\n",
      "2020-10-30 13:58:50,349 : INFO : EPOCH 1 - PROGRESS: at 69.94% examples, 232753 words/s, in_qsize 15, out_qsize 0\n",
      "2020-10-30 13:58:51,407 : INFO : EPOCH 1 - PROGRESS: at 73.19% examples, 233562 words/s, in_qsize 15, out_qsize 0\n",
      "2020-10-30 13:58:52,436 : INFO : EPOCH 1 - PROGRESS: at 75.78% examples, 232572 words/s, in_qsize 15, out_qsize 0\n",
      "2020-10-30 13:58:53,469 : INFO : EPOCH 1 - PROGRESS: at 78.62% examples, 232260 words/s, in_qsize 15, out_qsize 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gensim\\models\\word2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, sentences, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, compute_loss, callbacks)\u001b[0m\n\u001b[0;32m    722\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    723\u001b[0m         \"\"\"\n\u001b[1;32m--> 724\u001b[1;33m         return super(Word2Vec, self).train(\n\u001b[0m\u001b[0;32m    725\u001b[0m             \u001b[0msentences\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_alpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstart_alpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_alpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mend_alpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword_count\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mword_count\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gensim\\models\\base_any2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, sentences, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, compute_loss, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m   1061\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1062\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrunning_training_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1063\u001b[1;33m         return super(BaseWordEmbeddingsModel, self).train(\n\u001b[0m\u001b[0;32m   1064\u001b[0m             \u001b[0mdata_iterable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1065\u001b[0m             \u001b[0mtotal_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_alpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstart_alpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_alpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mend_alpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword_count\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mword_count\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gensim\\models\\base_any2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, data_iterable, corpus_file, epochs, total_examples, total_words, queue_factor, report_delay, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdata_iterable\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m                 trained_word_count_epoch, raw_word_count_epoch, job_tally_epoch = self._train_epoch(\n\u001b[0m\u001b[0;32m    551\u001b[0m                     \u001b[0mdata_iterable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcur_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcur_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m                     total_words=total_words, queue_factor=queue_factor, report_delay=report_delay)\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gensim\\models\\base_any2vec.py\u001b[0m in \u001b[0;36m_train_epoch\u001b[1;34m(self, data_iterable, cur_epoch, total_examples, total_words, queue_factor, report_delay)\u001b[0m\n\u001b[0;32m    484\u001b[0m             \u001b[0mthread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    485\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 486\u001b[1;33m         trained_word_count, raw_word_count, job_tally = self._log_epoch_progress(\n\u001b[0m\u001b[0;32m    487\u001b[0m             \u001b[0mprogress_queue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjob_queue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcur_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcur_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m             report_delay=report_delay, is_corpus_file_mode=False)\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gensim\\models\\base_any2vec.py\u001b[0m in \u001b[0;36m_log_epoch_progress\u001b[1;34m(self, progress_queue, job_queue, cur_epoch, total_examples, total_words, report_delay, is_corpus_file_mode)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0munfinished_worker_count\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m             \u001b[0mreport\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprogress_queue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# blocks if workers too slow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mreport\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# a thread reporting that it finished\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m                 \u001b[0munfinished_worker_count\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\queue.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    168\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m                 \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_qsize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 170\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    171\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"'timeout' must be a non-negative number\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    300\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 302\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v_model.train(documents, total_examples=len(documents), epochs=W2V_EPOCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = pickle.load(open(\"model.w2v\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-20-9e1a4c826e7b>:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  w2v_model.most_similar(\"love\")\n",
      "2020-10-30 13:59:59,764 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('luv', 0.5732780694961548),\n",
       " ('loves', 0.5623786449432373),\n",
       " ('loved', 0.5373271703720093),\n",
       " ('amazing', 0.5026600360870361),\n",
       " ('adore', 0.4942743182182312),\n",
       " ('looove', 0.47235167026519775),\n",
       " ('awesome', 0.4598265290260315),\n",
       " ('lovee', 0.45823755860328674),\n",
       " ('loveee', 0.4531649351119995),\n",
       " ('loooove', 0.442605197429657)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.most_similar(\"love\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df_train.text)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(\"Total words\", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "x_train = pad_sequences(tokenizer.texts_to_sequences(df_train.text), maxlen=SEQUENCE_LENGTH)\n",
    "x_test = pad_sequences(tokenizer.texts_to_sequences(df_test.text), maxlen=SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df_train.target.unique().tolist()\n",
    "labels.append(NEUTRAL)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(df_train.target.tolist())\n",
    "\n",
    "y_train = encoder.transform(df_train.target.tolist())\n",
    "y_test = encoder.transform(df_test.target.tolist())\n",
    "\n",
    "y_train = y_train.reshape(-1,1)\n",
    "y_test = y_test.reshape(-1,1)\n",
    "\n",
    "print(\"y_train\",y_train.shape)\n",
    "print(\"y_test\",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"x_train\", x_train.shape)\n",
    "print(\"y_train\", y_train.shape)\n",
    "print()\n",
    "print(\"x_test\", x_test.shape)\n",
    "print(\"y_test\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embedding Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((vocab_size, W2V_SIZE))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "  if word in w2v_model.wv:\n",
    "    embedding_matrix[i] = w2v_model.wv[word]\n",
    "print(embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(vocab_size, W2V_SIZE, weights=[embedding_matrix], input_length=SEQUENCE_LENGTH, trainable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(embedding_layer)\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=\"adam\",\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [ ReduceLROnPlateau(monitor='val_loss', patience=5, cooldown=0),\n",
    "              EarlyStopping(monitor='val_acc', min_delta=1e-4, patience=5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s164937\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.preprocessing.label module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.preprocessing. Anything that cannot be imported from sklearn.preprocessing is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\s164937\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator LabelEncoder from version 0.20.1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "modelw = pickle.load(open(\"model.w2v\", 'rb'))\n",
    "tokenizer = pickle.load(open(\"tokenizer.pkl\", \"rb\"))\n",
    "encoder = pickle.load(open(\"encoder.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelh = load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x_test' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "score = modelh.evaluate(x_test, y_test, batch_size=BATCH_SIZE)\n",
    "print()\n",
    "print(\"ACCURACY:\",score[1])\n",
    "print(\"LOSS:\",score[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    " \n",
    "epochs = range(len(acc))\n",
    " \n",
    "plt.plot(epochs, acc, 'b', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    " \n",
    "plt.figure()\n",
    " \n",
    "plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sentiment(score, include_neutral=True):\n",
    "    if include_neutral:        \n",
    "        label = NEUTRAL\n",
    "        if score <= SENTIMENT_THRESHOLDS[0]:\n",
    "            label = NEGATIVE\n",
    "        elif score >= SENTIMENT_THRESHOLDS[1]:\n",
    "            label = POSITIVE\n",
    "\n",
    "        return label\n",
    "    else:\n",
    "        return NEGATIVE if score < 0.5 else POSITIVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text, include_neutral=True):\n",
    "    start_at = time.time()\n",
    "    # Tokenize text\n",
    "    x_test = pad_sequences(tokenizer.texts_to_sequences([text]), maxlen=SEQUENCE_LENGTH)\n",
    "    # Predict\n",
    "    score = modelh.predict([x_test])[0]\n",
    "    # Decode sentiment\n",
    "    label = decode_sentiment(score, include_neutral=include_neutral)\n",
    "\n",
    "    return {\"label\": label, \"score\": float(score),\n",
    "       \"elapsed_time\": time.time()-start_at}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 'NEGATIVE',\n",
       " 'score': 0.22640293836593628,\n",
       " 'elapsed_time': 0.1934833526611328}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"Finish fast\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
